{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "Keras это высокоуровневая обертка над tensorflow. Но в текущих реализациях библиотеке tf они живут очень рядом. \n",
    "Когда мы собираем свои нейронки мы берем уже готовые слои из keras и добавляем что-то свое, если нам требуется.\n",
    "Но keras можно использовать без явного использования TF пытаясь свести задачу к fit-predict.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential\n",
    "Самое простое, что мы можем сделать это собирать слои последовательно друг за другом - займемся же этим!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers as L # подгружаем нужные модули. \n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в keras лежит несколько наборов данных. Для примера возьмем fashion_mnist - как mnist, но про предметы одежды :)\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=10**4, random_state=42)\n",
    "\n",
    "X_train = X_train/ 255.\n",
    "X_val = X_val/ 255.\n",
    "X_test = X_test/ 255.\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T-shirt/top'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[2])\n",
    "class_names[y_train[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1254902 , 0.14509804,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.34509804, 0.43921569,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00784314, 0.        , 0.00784314, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02745098, 0.46666667, 0.28235294,\n",
       "        0.21960784, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.08235294, 0.09803922,\n",
       "        0.1254902 , 0.08235294, 0.52941176, 0.23529412, 0.        ,\n",
       "        0.54901961, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.03529412, 0.15294118,\n",
       "        0.22745098, 0.25490196, 0.31764706, 0.23529412, 0.37254902,\n",
       "        0.17254902, 0.4       , 0.54901961, 0.1254902 , 0.00784314,\n",
       "        0.54117647, 0.09019608, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.4       , 0.49411765,\n",
       "        0.25490196, 0.08235294, 0.09803922, 0.09019608, 0.11764706,\n",
       "        0.        , 0.30196078, 0.63137255, 0.        , 0.39215686,\n",
       "        0.58431373, 0.09019608, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00784314, 0.        ,\n",
       "        0.        , 0.        , 0.02745098, 0.54901961, 0.41176471,\n",
       "        0.36470588, 0.49411765, 0.51372549, 0.65882353, 0.90588235,\n",
       "        0.67843137, 0.34509804, 0.71372549, 0.46666667, 0.00784314,\n",
       "        0.10980392, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.38431373, 0.51372549,\n",
       "        0.79607843, 0.52941176, 0.1372549 , 0.09803922, 0.        ,\n",
       "        0.52156863, 0.51372549, 0.37254902, 0.37254902, 0.07058824,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24705882, 0.59607843,\n",
       "        0.0627451 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00784314, 0.20784314, 0.23529412, 0.2745098 , 0.39215686,\n",
       "        0.11764706, 0.        , 0.00784314],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09803922, 0.32941176, 0.        ,\n",
       "        0.        , 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.1254902 , 0.14509804, 0.09803922, 0.28235294, 0.14509804,\n",
       "        0.50196078, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00784314, 0.        , 0.29019608, 0.03529412, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
       "        0.2627451 , 0.08235294, 0.17254902, 0.03529412, 0.        ,\n",
       "        0.2       , 0.36470588, 0.04313725],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00784314, 0.        ,\n",
       "        0.        , 0.        , 0.17254902, 0.30980392, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16470588,\n",
       "        0.22745098, 0.16470588, 0.25490196, 0.08235294, 0.        ,\n",
       "        0.        , 0.37254902, 0.2       ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.34509804, 0.23529412,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.2627451 ,\n",
       "        0.09803922, 0.10980392, 0.18039216, 0.        , 0.        ,\n",
       "        0.15294118, 0.62352941, 0.04313725],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.2627451 ,\n",
       "        0.2745098 , 0.00784314, 0.        , 0.        , 0.17254902,\n",
       "        0.08235294, 0.08235294, 0.2627451 , 0.31764706, 0.34509804,\n",
       "        0.58431373, 0.50196078, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2627451 , 0.43921569, 0.09019608, 0.1254902 , 0.19215686,\n",
       "        0.22745098, 0.18039216, 0.23529412, 0.63921569, 0.41176471,\n",
       "        0.4       , 0.43921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.31764706, 0.2       , 0.10980392, 0.11764706, 0.04313725,\n",
       "        0.04313725, 0.25490196, 0.23529412, 0.34509804, 0.23529412,\n",
       "        0.1372549 , 0.4       , 0.74901961, 0.44705882, 0.70588235,\n",
       "        0.4       , 0.3372549 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29019608,\n",
       "        0.25490196, 0.20784314, 0.19215686, 0.20784314, 0.16470588,\n",
       "        0.17254902, 0.15294118, 0.28235294, 0.29019608, 0.0627451 ,\n",
       "        0.48235294, 0.73333333, 0.0627451 , 0.        , 0.65098039,\n",
       "        0.50196078, 0.19215686, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.34509804,\n",
       "        0.0627451 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02745098, 0.        , 0.35686275, 0.15294118, 0.45490196,\n",
       "        0.71372549, 0.        , 0.        , 0.        , 0.51372549,\n",
       "        0.45490196, 0.14509804, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21960784,\n",
       "        0.77647059, 0.61176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0627451 , 0.2745098 , 0.20784314, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.3372549 ,\n",
       "        0.45490196, 0.11764706, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.10980392,\n",
       "        0.24705882, 0.58431373, 0.52156863, 0.01568627, 0.        ,\n",
       "        0.        , 0.46666667, 0.54901961, 0.56862745, 0.02745098,\n",
       "        0.        , 0.01568627, 0.00784314, 0.        , 0.2745098 ,\n",
       "        0.45490196, 0.07058824, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05490196, 0.16470588, 0.18039216, 0.15294118,\n",
       "        0.09019608, 0.08235294, 0.46666667, 0.41176471, 0.        ,\n",
       "        0.23529412, 0.38431373, 0.66666667, 0.04313725, 0.        ,\n",
       "        0.        , 0.00784314, 0.01568627, 0.        , 0.29019608,\n",
       "        0.45490196, 0.05490196, 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.00784314,\n",
       "        0.39215686, 0.32941176, 0.30196078, 0.72156863, 0.9254902 ,\n",
       "        0.34509804, 0.08235294, 0.11764706, 0.30196078, 0.45490196,\n",
       "        0.24705882, 0.54117647, 0.57647059, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.        , 0.24705882,\n",
       "        0.41960784, 0.01568627, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.42745098, 0.24705882, 0.01568627, 0.02745098, 0.39215686,\n",
       "        0.21960784, 0.07058824, 0.09803922, 0.1372549 , 0.29019608,\n",
       "        0.44705882, 0.46666667, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01568627, 0.        , 0.23529412,\n",
       "        0.41176471, 0.00784314, 0.        ],\n",
       "       [0.00784314, 0.08235294, 0.32941176, 0.49411765, 0.09803922,\n",
       "        0.11764706, 0.77647059, 0.09019608, 0.01568627, 0.04313725,\n",
       "        0.09019608, 0.16470588, 0.15294118, 0.10980392, 0.02745098,\n",
       "        0.91372549, 0.08235294, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.        , 0.24705882,\n",
       "        0.41960784, 0.        , 0.        ],\n",
       "       [0.44705882, 0.54117647, 0.2745098 , 0.19215686, 0.15294118,\n",
       "        0.09019608, 0.84313725, 0.2745098 , 0.05490196, 0.10980392,\n",
       "        0.1372549 , 0.20784314, 0.23529412, 0.0627451 , 0.66666667,\n",
       "        0.37254902, 0.        , 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.        , 0.28235294,\n",
       "        0.45490196, 0.00784314, 0.        ],\n",
       "       [0.05490196, 0.56862745, 0.73333333, 0.69411765, 0.54117647,\n",
       "        0.10980392, 0.45490196, 0.74117647, 0.09019608, 0.11764706,\n",
       "        0.19215686, 0.15294118, 0.05490196, 0.31764706, 0.79607843,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
       "        0.        , 0.        , 0.00784314, 0.        , 0.11764706,\n",
       "        0.31764706, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.09019608, 0.54901961, 0.76078431,\n",
       "        0.73333333, 0.55686275, 0.85882353, 0.67843137, 0.54901961,\n",
       "        0.46666667, 0.41176471, 0.4745098 , 0.70588235, 0.02745098,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01568627, 0.        , 0.37254902,\n",
       "        1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1254902 , 0.09803922, 0.31764706, 0.30196078,\n",
       "        0.4       , 0.41176471, 0.36470588, 0.03529412, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.        , 0.21960784,\n",
       "        0.68627451, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 0, ..., 6, 6, 1], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для того, чтобы учить через cross_entropy нам нужно сделать OHE таргетам. И эта функция есть в keras!\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_ohe = to_categorical(y_train)\n",
    "y_test_ohe = to_categorical(y_test)\n",
    "y_val_ohe = to_categorical(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 1s 21us/sample - loss: 1.8986 - categorical_accuracy: 0.4763 - val_loss: 1.4738 - val_categorical_accuracy: 0.6307\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 1.2020 - categorical_accuracy: 0.6655 - val_loss: 1.0251 - val_categorical_accuracy: 0.6802\n"
     ]
    }
   ],
   "source": [
    "## Первая простая нейронка\n",
    "\n",
    "tf.random.set_seed(42) # фиксируем random_seed\n",
    "\n",
    "model = Sequential(name = 'first_try')\n",
    "model.add(L.Input(shape = (28,28))) # входной нейрон с данными. Его обычно можно опускать, сразу передавая \n",
    "# в нейрон размерность. Но Dense ячейки не умеют работать с картинками, поэтому оставляем Input\n",
    "model.add(L.Flatten()) # разворачиваем картинку в вектор\n",
    "model.add(L.Dense(100,  kernel_initializer='random_normal',name='First')) # можно именовать и потом брать слои по именам\n",
    "model.add(L.ReLU()) # добавляем активацию\n",
    "model.add(L.Dense(10, kernel_initializer = 'random_normal',name='Output'))\n",
    "model.add(L.Softmax())\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4) # так же нам нужно указать оптимайзер\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) # и собрать нашу модель, указав метрики,loss и оптимизатор\n",
    "\n",
    "\n",
    "history1 = model.fit(X_train,y_train_ohe,batch_size=500,epochs=2,validation_data = (X_val,y_val_ohe))\n",
    "# и процесс обучения. Задаем количество эпох, размер батча и валидационную часть наших данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.8986167120933533, 1.2020430505275725],\n",
       " 'categorical_accuracy': [0.47632, 0.66554],\n",
       " 'val_loss': [1.4737698197364808, 1.025083103775978],\n",
       " 'val_categorical_accuracy': [0.6307, 0.6802]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.8986167120933533, 1.2020430505275725],\n",
       " 'categorical_accuracy': [0.47632, 0.66554],\n",
       " 'val_loss': [1.4737698197364808, 1.025083103775978],\n",
       " 'val_categorical_accuracy': [0.6307, 0.6802]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 1s 15us/sample - loss: 1.8141 - categorical_accuracy: 0.4979 - val_loss: 1.3973 - val_categorical_accuracy: 0.6449\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 1.1440 - categorical_accuracy: 0.6720 - val_loss: 0.9782 - val_categorical_accuracy: 0.6839\n"
     ]
    }
   ],
   "source": [
    "# Эту же модель можно записать чуть в меньшее количество строчек кода\n",
    "model = Sequential(name = 'first_try')\n",
    "model.add(L.Input(shape = (28,28))) \n",
    "model.add(L.Flatten()) \n",
    "model.add(L.Dense(100,  kernel_initializer='random_normal',name='First',activation='relu')) # можно именовать и потом брать слои по именам\n",
    "model.add(L.Dense(10, kernel_initializer = 'random_normal',name='Output',activation='softmax'))\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4) \n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) \n",
    "\n",
    "history1 = model.fit(X_train,y_train_ohe,batch_size=500,epochs=2,validation_data = (X_val,y_val_ohe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "?L.Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из приятного - все в таком подходе можно кастомизировать под себя!\n",
    "Но пока продолжим рассмотрение о следующем подходе сборки моделей.\n",
    "Класс Sequential не дает нам вообще никакой гибкости, позволяя набирать слои только последовательно.\n",
    "Что же у нас есть новый герой  - Model.\n",
    "Он позволяет собирать сетки практически любой архитектуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model  # подгружаем нужные модули. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = 'uniform'\n",
    "act = 'relu'\n",
    "\n",
    "input_tensor = L.Input(shape=(28, 28)) # задаем вход\n",
    "x = L.Flatten()(input_tensor)# применение нейрона к входу\n",
    "x = L.Dense(100, kernel_initializer=init, activation=act)(x) # повторяем всю логику сколько нам надо раз\n",
    "x = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "output_tensor = L.Dense(10, kernel_initializer=init, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(input_tensor, output_tensor) # Keras под капотом сам собирает граф.\n",
    "# Если он может получить из входа выхода то вы великолепны.\n",
    "\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 1s 20us/sample - loss: 1.7316 - categorical_accuracy: 0.4919 - val_loss: 1.1618 - val_categorical_accuracy: 0.6287\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 1s 12us/sample - loss: 0.9691 - categorical_accuracy: 0.6527 - val_loss: 0.8632 - val_categorical_accuracy: 0.6665\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train_ohe,batch_size=500,epochs=2,validation_data = (X_val,y_val_ohe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой подход позволяет делать практически любой гибкости нейронки. Как пример - двухголовая!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_1 (InputLayer)            [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_2 (InputLayer)            [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 784)          0           Input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 784)          0           Input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 100)          78500       flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 100)          78500       flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 100)          10100       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 100)          10100       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           dense_8[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 10)           2010        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 179,210\n",
      "Trainable params: 179,210\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_1 = L.Input(shape=(28, 28),name='Input_1')\n",
    "input_2 = L.Input(shape=(28, 28),name='Input_2')\n",
    "\n",
    "x1 = L.Flatten()(input_1)\n",
    "x1 = L.Dense(100, kernel_initializer=init, activation=act)(x1)\n",
    "x1 = L.Dense(100, kernel_initializer=init, activation=act)(x1)\n",
    "\n",
    "x2 = L.Flatten()(input_2)\n",
    "x2 = L.Dense(100, kernel_initializer=init, activation=act)(x2)\n",
    "x2 = L.Dense(100, kernel_initializer=init, activation=act)(x2)\n",
    "\n",
    "x = L.concatenate([x1, x2]) # Волшебное слово, которое позволяет нам соеденять несколько потоков наших данных\n",
    "output = L.Dense(10, kernel_initializer=init, activation='softmax',name='out')(x)\n",
    "\n",
    "model = keras.Model([input_1, input_2], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.3629 - categorical_accuracy: 0.5865 - val_loss: 0.8267 - val_categorical_accuracy: 0.6792\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 1s 20us/sample - loss: 0.7145 - categorical_accuracy: 0.7403 - val_loss: 0.6616 - val_categorical_accuracy: 0.7659\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train,X_train],[y_train_ohe,..,..],batch_size=500,epochs=2,validation_data = ([X_val,X_val],y_val_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit({'Input_1':X_train,'Input_2':X_train,'out':y_train_ohe},batch_size=500,epochs=2,validation_data = ([X_val,X_val],y_val_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нужно для винды, если не видит путь до graphviz\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model) # можно нарисовать модельку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Несколько выходов и функций потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 784)          0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 100)          78500       flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 100)          78500       flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 100)          78500       flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            101         dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1010        dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            101         dense_42[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 236,712\n",
      "Trainable params: 236,712\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "init = 'uniform'\n",
    "act = 'relu'\n",
    "\n",
    "input_tensor = L.Input(shape=(28, 28))\n",
    "\n",
    "x = L.Flatten()(input_tensor)\n",
    "x1 = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "x2 = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "x3 = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "\n",
    "output_1 = L.Dense(1, kernel_initializer=init, activation='sigmoid',name='gender')(x1)\n",
    "output_2 = L.Dense(10, kernel_initializer=init, activation='softmax',name='income')(x2)\n",
    "output_3 = L.Dense(1, kernel_initializer=init,name='age')(x3)\n",
    "\n",
    "model = keras.Model(input_tensor, [output_1, output_2, output_3])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы модель не переобучилась под самую большую функцию потерь\n",
    "# их можно взвесить\n",
    "model.compile(optimizer='adam', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "                                    loss_weights=[0.25, 1., 10.])\n",
    "\n",
    "\n",
    "# если дали выходам имена, можно вот так: \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "                    \n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помните статью про то, как люди рисовали функции потерь? [Теперь появилась галерея!](https://losslandscape.com/gallery/) Есть подход как skip-connection, он сильно меняет нашу функцию.\n",
    "\n",
    "![](https://i.stack.imgur.com/UDvbg.png)\n",
    "\n",
    "Такую модель нельзя собрать через `Sequence`-стиль, но можно через функциональный стиль. Давайте попробуем сделать это. Заодно посмотрим насколько сильно в нашей ситуации будет меняться траектория обучения. (Сравним обычный 6-ти слойный персептрон и с прокидыванием инфы, например со 2 слоя на 5ый). Ну и также сразу поэксперементируем с функциями активаций и batchnorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 1s 14us/sample - loss: 1.5032 - categorical_accuracy: 0.5423 - val_loss: 1.1158 - val_categorical_accuracy: 0.6625\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 1.0000 - categorical_accuracy: 0.6889 - val_loss: 0.9364 - val_categorical_accuracy: 0.6992\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.8778 - categorical_accuracy: 0.7185 - val_loss: 0.8535 - val_categorical_accuracy: 0.7211\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.8105 - categorical_accuracy: 0.7379 - val_loss: 0.8011 - val_categorical_accuracy: 0.7396\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.7652 - categorical_accuracy: 0.7538 - val_loss: 0.7633 - val_categorical_accuracy: 0.7548\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.7313 - categorical_accuracy: 0.7640 - val_loss: 0.7343 - val_categorical_accuracy: 0.7607\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.7047 - categorical_accuracy: 0.7727 - val_loss: 0.7106 - val_categorical_accuracy: 0.7712\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6828 - categorical_accuracy: 0.7798 - val_loss: 0.6912 - val_categorical_accuracy: 0.7743\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6644 - categorical_accuracy: 0.7851 - val_loss: 0.6742 - val_categorical_accuracy: 0.7801\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.6486 - categorical_accuracy: 0.7911 - val_loss: 0.6601 - val_categorical_accuracy: 0.7827\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6347 - categorical_accuracy: 0.7949 - val_loss: 0.6472 - val_categorical_accuracy: 0.7861\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.6224 - categorical_accuracy: 0.7985 - val_loss: 0.6357 - val_categorical_accuracy: 0.7910\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6114 - categorical_accuracy: 0.8018 - val_loss: 0.6259 - val_categorical_accuracy: 0.7931\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.6018 - categorical_accuracy: 0.8048 - val_loss: 0.6162 - val_categorical_accuracy: 0.7962\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5927 - categorical_accuracy: 0.8069 - val_loss: 0.6080 - val_categorical_accuracy: 0.7988\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5845 - categorical_accuracy: 0.8098 - val_loss: 0.6000 - val_categorical_accuracy: 0.8028\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5771 - categorical_accuracy: 0.8112 - val_loss: 0.5929 - val_categorical_accuracy: 0.8042\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 1s 11us/sample - loss: 0.5701 - categorical_accuracy: 0.8139 - val_loss: 0.5863 - val_categorical_accuracy: 0.8076\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5639 - categorical_accuracy: 0.8145 - val_loss: 0.5800 - val_categorical_accuracy: 0.8095\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5578 - categorical_accuracy: 0.8169 - val_loss: 0.5742 - val_categorical_accuracy: 0.8118\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5521 - categorical_accuracy: 0.8186 - val_loss: 0.5690 - val_categorical_accuracy: 0.8130\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5470 - categorical_accuracy: 0.8201 - val_loss: 0.5639 - val_categorical_accuracy: 0.8144\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5420 - categorical_accuracy: 0.8214 - val_loss: 0.5591 - val_categorical_accuracy: 0.8170\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5374 - categorical_accuracy: 0.8227 - val_loss: 0.5549 - val_categorical_accuracy: 0.8167\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5332 - categorical_accuracy: 0.8250 - val_loss: 0.5509 - val_categorical_accuracy: 0.8178\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.5289 - categorical_accuracy: 0.8256 - val_loss: 0.5468 - val_categorical_accuracy: 0.8200\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.5250 - categorical_accuracy: 0.8268 - val_loss: 0.5427 - val_categorical_accuracy: 0.8214\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5213 - categorical_accuracy: 0.8281 - val_loss: 0.5392 - val_categorical_accuracy: 0.8202\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5177 - categorical_accuracy: 0.8297 - val_loss: 0.5361 - val_categorical_accuracy: 0.8223\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5145 - categorical_accuracy: 0.8297 - val_loss: 0.5330 - val_categorical_accuracy: 0.8236\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5111 - categorical_accuracy: 0.8313 - val_loss: 0.5296 - val_categorical_accuracy: 0.8227\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.5082 - categorical_accuracy: 0.8319 - val_loss: 0.5262 - val_categorical_accuracy: 0.8252\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.5052 - categorical_accuracy: 0.8329 - val_loss: 0.5232 - val_categorical_accuracy: 0.8250\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5023 - categorical_accuracy: 0.8341 - val_loss: 0.5206 - val_categorical_accuracy: 0.8263\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4996 - categorical_accuracy: 0.8349 - val_loss: 0.5179 - val_categorical_accuracy: 0.8261\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4971 - categorical_accuracy: 0.8356 - val_loss: 0.5155 - val_categorical_accuracy: 0.8273\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.4947 - categorical_accuracy: 0.8362 - val_loss: 0.5129 - val_categorical_accuracy: 0.8272\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.4923 - categorical_accuracy: 0.8368 - val_loss: 0.5105 - val_categorical_accuracy: 0.8292\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4899 - categorical_accuracy: 0.8376 - val_loss: 0.5083 - val_categorical_accuracy: 0.8291\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4878 - categorical_accuracy: 0.8390 - val_loss: 0.5061 - val_categorical_accuracy: 0.8294\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4855 - categorical_accuracy: 0.8389 - val_loss: 0.5041 - val_categorical_accuracy: 0.8299\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4836 - categorical_accuracy: 0.8403 - val_loss: 0.5020 - val_categorical_accuracy: 0.8303\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 1s 10us/sample - loss: 0.4815 - categorical_accuracy: 0.8406 - val_loss: 0.5002 - val_categorical_accuracy: 0.8318\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4796 - categorical_accuracy: 0.8409 - val_loss: 0.4981 - val_categorical_accuracy: 0.8313\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4777 - categorical_accuracy: 0.8417 - val_loss: 0.4964 - val_categorical_accuracy: 0.8323\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4759 - categorical_accuracy: 0.8425 - val_loss: 0.4946 - val_categorical_accuracy: 0.8334\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4741 - categorical_accuracy: 0.8433 - val_loss: 0.4933 - val_categorical_accuracy: 0.8332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4726 - categorical_accuracy: 0.8435 - val_loss: 0.4910 - val_categorical_accuracy: 0.8346\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4707 - categorical_accuracy: 0.8433 - val_loss: 0.4903 - val_categorical_accuracy: 0.8346\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.4695 - categorical_accuracy: 0.8444 - val_loss: 0.4886 - val_categorical_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4678 - categorical_accuracy: 0.8449 - val_loss: 0.4865 - val_categorical_accuracy: 0.8361\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4662 - categorical_accuracy: 0.8451 - val_loss: 0.4854 - val_categorical_accuracy: 0.8355\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4646 - categorical_accuracy: 0.8453 - val_loss: 0.4836 - val_categorical_accuracy: 0.8361\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4633 - categorical_accuracy: 0.8458 - val_loss: 0.4828 - val_categorical_accuracy: 0.8357\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4621 - categorical_accuracy: 0.8464 - val_loss: 0.4812 - val_categorical_accuracy: 0.8367\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4607 - categorical_accuracy: 0.8467 - val_loss: 0.4801 - val_categorical_accuracy: 0.8368\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4592 - categorical_accuracy: 0.8467 - val_loss: 0.4785 - val_categorical_accuracy: 0.8366\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4580 - categorical_accuracy: 0.8478 - val_loss: 0.4772 - val_categorical_accuracy: 0.8366\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4568 - categorical_accuracy: 0.8484 - val_loss: 0.4764 - val_categorical_accuracy: 0.8371\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4556 - categorical_accuracy: 0.8484 - val_loss: 0.4752 - val_categorical_accuracy: 0.8383\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4544 - categorical_accuracy: 0.8488 - val_loss: 0.4738 - val_categorical_accuracy: 0.8378\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4534 - categorical_accuracy: 0.8488 - val_loss: 0.4729 - val_categorical_accuracy: 0.8389\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4522 - categorical_accuracy: 0.8496 - val_loss: 0.4720 - val_categorical_accuracy: 0.8384\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4510 - categorical_accuracy: 0.8501 - val_loss: 0.4708 - val_categorical_accuracy: 0.8389\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4501 - categorical_accuracy: 0.8499 - val_loss: 0.4696 - val_categorical_accuracy: 0.8392\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4489 - categorical_accuracy: 0.8507 - val_loss: 0.4687 - val_categorical_accuracy: 0.8396\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4479 - categorical_accuracy: 0.8508 - val_loss: 0.4677 - val_categorical_accuracy: 0.8391\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4470 - categorical_accuracy: 0.8508 - val_loss: 0.4666 - val_categorical_accuracy: 0.8392\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4460 - categorical_accuracy: 0.8509 - val_loss: 0.4666 - val_categorical_accuracy: 0.8398\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4452 - categorical_accuracy: 0.8513 - val_loss: 0.4649 - val_categorical_accuracy: 0.8399\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4442 - categorical_accuracy: 0.8519 - val_loss: 0.4642 - val_categorical_accuracy: 0.8400\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4431 - categorical_accuracy: 0.8520 - val_loss: 0.4633 - val_categorical_accuracy: 0.8410\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4426 - categorical_accuracy: 0.8524 - val_loss: 0.4626 - val_categorical_accuracy: 0.8408\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4415 - categorical_accuracy: 0.8525 - val_loss: 0.4617 - val_categorical_accuracy: 0.8422\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4407 - categorical_accuracy: 0.8529 - val_loss: 0.4612 - val_categorical_accuracy: 0.8424\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4398 - categorical_accuracy: 0.8528 - val_loss: 0.4601 - val_categorical_accuracy: 0.8423\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4390 - categorical_accuracy: 0.8532 - val_loss: 0.4592 - val_categorical_accuracy: 0.8421\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4381 - categorical_accuracy: 0.8533 - val_loss: 0.4586 - val_categorical_accuracy: 0.8428\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4376 - categorical_accuracy: 0.8536 - val_loss: 0.4579 - val_categorical_accuracy: 0.8422\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4367 - categorical_accuracy: 0.8537 - val_loss: 0.4570 - val_categorical_accuracy: 0.8426\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4360 - categorical_accuracy: 0.8536 - val_loss: 0.4564 - val_categorical_accuracy: 0.8424\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4351 - categorical_accuracy: 0.8544 - val_loss: 0.4562 - val_categorical_accuracy: 0.8434\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4345 - categorical_accuracy: 0.8548 - val_loss: 0.4552 - val_categorical_accuracy: 0.8431\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4338 - categorical_accuracy: 0.8547 - val_loss: 0.4544 - val_categorical_accuracy: 0.8433\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4331 - categorical_accuracy: 0.8547 - val_loss: 0.4538 - val_categorical_accuracy: 0.8434\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4324 - categorical_accuracy: 0.8547 - val_loss: 0.4532 - val_categorical_accuracy: 0.8442\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4316 - categorical_accuracy: 0.8552 - val_loss: 0.4526 - val_categorical_accuracy: 0.8444\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4312 - categorical_accuracy: 0.8554 - val_loss: 0.4523 - val_categorical_accuracy: 0.8445\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4304 - categorical_accuracy: 0.8557 - val_loss: 0.4515 - val_categorical_accuracy: 0.8444\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4298 - categorical_accuracy: 0.8553 - val_loss: 0.4506 - val_categorical_accuracy: 0.8443\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4292 - categorical_accuracy: 0.8559 - val_loss: 0.4502 - val_categorical_accuracy: 0.8448\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4285 - categorical_accuracy: 0.8560 - val_loss: 0.4499 - val_categorical_accuracy: 0.8447\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4280 - categorical_accuracy: 0.8562 - val_loss: 0.4493 - val_categorical_accuracy: 0.8449\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4273 - categorical_accuracy: 0.8559 - val_loss: 0.4491 - val_categorical_accuracy: 0.8449\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4268 - categorical_accuracy: 0.8566 - val_loss: 0.4491 - val_categorical_accuracy: 0.8451\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4263 - categorical_accuracy: 0.8565 - val_loss: 0.4481 - val_categorical_accuracy: 0.8460\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4257 - categorical_accuracy: 0.8565 - val_loss: 0.4472 - val_categorical_accuracy: 0.8457\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4251 - categorical_accuracy: 0.8573 - val_loss: 0.4469 - val_categorical_accuracy: 0.8458\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4247 - categorical_accuracy: 0.8568 - val_loss: 0.4467 - val_categorical_accuracy: 0.8451\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4240 - categorical_accuracy: 0.8573 - val_loss: 0.4457 - val_categorical_accuracy: 0.8465\n"
     ]
    }
   ],
   "source": [
    "## Соберите с батчнормом и релу\n",
    "# history_simple_BN_and_init\n",
    "\n",
    "\n",
    "init = 'he_uniform'\n",
    "act = 'relu'\n",
    "\n",
    "input_tensor = L.Input(shape=(28, 28)) # задаем вход\n",
    "x = L.Flatten()(input_tensor)# применение нейрона к входу\n",
    "x1 = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "x1 = L.BatchNormalization()(x1)\n",
    "x2 = L.Dense(100, kernel_initializer=init, activation=act)(x1)\n",
    "x3 = L.Dense(100, kernel_initializer=init, activation=act)(x2) # повторяем всю логику сколько нам надо раз\n",
    "x4 = L.Dense(100, kernel_initializer=init, activation=act)(x3)\n",
    "x4 = L.BatchNormalization()(x4)\n",
    "x5 = L.Dense(100, kernel_initializer=init, activation=act)(x4)\n",
    "output_tensor = L.Dense(10, kernel_initializer=init, activation='softmax')(x)\n",
    "\n",
    "simple_BN_and_init = keras.Model(input_tensor, output_tensor) # Keras под капотом сам собирает граф.\n",
    "# Если он может получить из входа выхода то вы великолепны.\n",
    "\n",
    "simple_BN_and_init.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) \n",
    "\n",
    "history_simple_BN_and_init = simple_BN_and_init.fit(X_train,y_train_ohe,\n",
    "                                                    batch_size=500,\n",
    "                                                    epochs=100,validation_data = (X_val,y_val_ohe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 1s 15us/sample - loss: 1.4291 - categorical_accuracy: 0.5510 - val_loss: 1.0116 - val_categorical_accuracy: 0.6976\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.9045 - categorical_accuracy: 0.7236 - val_loss: 0.8541 - val_categorical_accuracy: 0.7298\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.7993 - categorical_accuracy: 0.7513 - val_loss: 0.7839 - val_categorical_accuracy: 0.7507\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.7432 - categorical_accuracy: 0.7662 - val_loss: 0.7403 - val_categorical_accuracy: 0.7633\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.7062 - categorical_accuracy: 0.7765 - val_loss: 0.7096 - val_categorical_accuracy: 0.7704\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6787 - categorical_accuracy: 0.7840 - val_loss: 0.6860 - val_categorical_accuracy: 0.7802\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6574 - categorical_accuracy: 0.7908 - val_loss: 0.6665 - val_categorical_accuracy: 0.7855\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6398 - categorical_accuracy: 0.7961 - val_loss: 0.6510 - val_categorical_accuracy: 0.7882\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6251 - categorical_accuracy: 0.8003 - val_loss: 0.6370 - val_categorical_accuracy: 0.7938\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6124 - categorical_accuracy: 0.8033 - val_loss: 0.6258 - val_categorical_accuracy: 0.7952\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6014 - categorical_accuracy: 0.8061 - val_loss: 0.6156 - val_categorical_accuracy: 0.7970\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5915 - categorical_accuracy: 0.8087 - val_loss: 0.6061 - val_categorical_accuracy: 0.8010\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5827 - categorical_accuracy: 0.8112 - val_loss: 0.5984 - val_categorical_accuracy: 0.8024\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5752 - categorical_accuracy: 0.8131 - val_loss: 0.5902 - val_categorical_accuracy: 0.8053\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5677 - categorical_accuracy: 0.8153 - val_loss: 0.5837 - val_categorical_accuracy: 0.8067\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5612 - categorical_accuracy: 0.8172 - val_loss: 0.5772 - val_categorical_accuracy: 0.8097\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5553 - categorical_accuracy: 0.8184 - val_loss: 0.5714 - val_categorical_accuracy: 0.8115\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5495 - categorical_accuracy: 0.8211 - val_loss: 0.5661 - val_categorical_accuracy: 0.8128\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5445 - categorical_accuracy: 0.8218 - val_loss: 0.5610 - val_categorical_accuracy: 0.8146\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.5396 - categorical_accuracy: 0.8232 - val_loss: 0.5561 - val_categorical_accuracy: 0.8154\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5350 - categorical_accuracy: 0.8248 - val_loss: 0.5520 - val_categorical_accuracy: 0.8171\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5307 - categorical_accuracy: 0.8258 - val_loss: 0.5478 - val_categorical_accuracy: 0.8169\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5266 - categorical_accuracy: 0.8274 - val_loss: 0.5437 - val_categorical_accuracy: 0.8182\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5228 - categorical_accuracy: 0.8290 - val_loss: 0.5403 - val_categorical_accuracy: 0.8205\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5193 - categorical_accuracy: 0.8299 - val_loss: 0.5370 - val_categorical_accuracy: 0.8199\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5158 - categorical_accuracy: 0.8306 - val_loss: 0.5336 - val_categorical_accuracy: 0.8225\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5125 - categorical_accuracy: 0.8314 - val_loss: 0.5300 - val_categorical_accuracy: 0.8220\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5094 - categorical_accuracy: 0.8323 - val_loss: 0.5271 - val_categorical_accuracy: 0.8232\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5063 - categorical_accuracy: 0.8331 - val_loss: 0.5246 - val_categorical_accuracy: 0.8245\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5036 - categorical_accuracy: 0.8344 - val_loss: 0.5220 - val_categorical_accuracy: 0.8246\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5007 - categorical_accuracy: 0.8345 - val_loss: 0.5190 - val_categorical_accuracy: 0.8262\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4983 - categorical_accuracy: 0.8357 - val_loss: 0.5163 - val_categorical_accuracy: 0.8279\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4957 - categorical_accuracy: 0.8367 - val_loss: 0.5136 - val_categorical_accuracy: 0.8279\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4932 - categorical_accuracy: 0.8371 - val_loss: 0.5114 - val_categorical_accuracy: 0.8279\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4909 - categorical_accuracy: 0.8381 - val_loss: 0.5090 - val_categorical_accuracy: 0.8288\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4887 - categorical_accuracy: 0.8385 - val_loss: 0.5070 - val_categorical_accuracy: 0.8288\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4867 - categorical_accuracy: 0.8391 - val_loss: 0.5048 - val_categorical_accuracy: 0.8305\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4846 - categorical_accuracy: 0.8399 - val_loss: 0.5027 - val_categorical_accuracy: 0.8306\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4824 - categorical_accuracy: 0.8406 - val_loss: 0.5007 - val_categorical_accuracy: 0.8302\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4806 - categorical_accuracy: 0.8406 - val_loss: 0.4989 - val_categorical_accuracy: 0.8316\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4786 - categorical_accuracy: 0.8413 - val_loss: 0.4972 - val_categorical_accuracy: 0.8320\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4769 - categorical_accuracy: 0.8420 - val_loss: 0.4953 - val_categorical_accuracy: 0.8319\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4751 - categorical_accuracy: 0.8421 - val_loss: 0.4937 - val_categorical_accuracy: 0.8327\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4734 - categorical_accuracy: 0.8428 - val_loss: 0.4918 - val_categorical_accuracy: 0.8331\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4716 - categorical_accuracy: 0.8432 - val_loss: 0.4904 - val_categorical_accuracy: 0.8335\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4701 - categorical_accuracy: 0.8436 - val_loss: 0.4888 - val_categorical_accuracy: 0.8335\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4684 - categorical_accuracy: 0.8439 - val_loss: 0.4876 - val_categorical_accuracy: 0.8346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4671 - categorical_accuracy: 0.8449 - val_loss: 0.4855 - val_categorical_accuracy: 0.8345\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4654 - categorical_accuracy: 0.8448 - val_loss: 0.4849 - val_categorical_accuracy: 0.8350\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4644 - categorical_accuracy: 0.8456 - val_loss: 0.4835 - val_categorical_accuracy: 0.8341\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4628 - categorical_accuracy: 0.8458 - val_loss: 0.4816 - val_categorical_accuracy: 0.8356\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4614 - categorical_accuracy: 0.8471 - val_loss: 0.4806 - val_categorical_accuracy: 0.8341\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4598 - categorical_accuracy: 0.8468 - val_loss: 0.4789 - val_categorical_accuracy: 0.8362\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4587 - categorical_accuracy: 0.8469 - val_loss: 0.4783 - val_categorical_accuracy: 0.8345\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4576 - categorical_accuracy: 0.8475 - val_loss: 0.4768 - val_categorical_accuracy: 0.8355\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4563 - categorical_accuracy: 0.8478 - val_loss: 0.4759 - val_categorical_accuracy: 0.8357\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4551 - categorical_accuracy: 0.8481 - val_loss: 0.4744 - val_categorical_accuracy: 0.8358\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4538 - categorical_accuracy: 0.8482 - val_loss: 0.4732 - val_categorical_accuracy: 0.8362\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4528 - categorical_accuracy: 0.8489 - val_loss: 0.4724 - val_categorical_accuracy: 0.8377\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4517 - categorical_accuracy: 0.8489 - val_loss: 0.4714 - val_categorical_accuracy: 0.8372\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4506 - categorical_accuracy: 0.8497 - val_loss: 0.4701 - val_categorical_accuracy: 0.8367\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4497 - categorical_accuracy: 0.8493 - val_loss: 0.4693 - val_categorical_accuracy: 0.8370\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4486 - categorical_accuracy: 0.8498 - val_loss: 0.4684 - val_categorical_accuracy: 0.8364\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4475 - categorical_accuracy: 0.8504 - val_loss: 0.4674 - val_categorical_accuracy: 0.8377\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4466 - categorical_accuracy: 0.8502 - val_loss: 0.4663 - val_categorical_accuracy: 0.8391\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4456 - categorical_accuracy: 0.8505 - val_loss: 0.4654 - val_categorical_accuracy: 0.8383\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4447 - categorical_accuracy: 0.8511 - val_loss: 0.4645 - val_categorical_accuracy: 0.8383\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4438 - categorical_accuracy: 0.8514 - val_loss: 0.4635 - val_categorical_accuracy: 0.8379\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4428 - categorical_accuracy: 0.8513 - val_loss: 0.4636 - val_categorical_accuracy: 0.8374\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4421 - categorical_accuracy: 0.8520 - val_loss: 0.4620 - val_categorical_accuracy: 0.8388\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4411 - categorical_accuracy: 0.8522 - val_loss: 0.4613 - val_categorical_accuracy: 0.8390\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4401 - categorical_accuracy: 0.8521 - val_loss: 0.4605 - val_categorical_accuracy: 0.8391\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4397 - categorical_accuracy: 0.8521 - val_loss: 0.4598 - val_categorical_accuracy: 0.8393\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4387 - categorical_accuracy: 0.8529 - val_loss: 0.4590 - val_categorical_accuracy: 0.8409\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4379 - categorical_accuracy: 0.8530 - val_loss: 0.4586 - val_categorical_accuracy: 0.8402\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4371 - categorical_accuracy: 0.8529 - val_loss: 0.4575 - val_categorical_accuracy: 0.8407\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4363 - categorical_accuracy: 0.8530 - val_loss: 0.4568 - val_categorical_accuracy: 0.8413\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4355 - categorical_accuracy: 0.8536 - val_loss: 0.4562 - val_categorical_accuracy: 0.8411\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4350 - categorical_accuracy: 0.8537 - val_loss: 0.4555 - val_categorical_accuracy: 0.8419\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4342 - categorical_accuracy: 0.8534 - val_loss: 0.4547 - val_categorical_accuracy: 0.8409\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4335 - categorical_accuracy: 0.8542 - val_loss: 0.4541 - val_categorical_accuracy: 0.8429\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4326 - categorical_accuracy: 0.8543 - val_loss: 0.4540 - val_categorical_accuracy: 0.8427\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4321 - categorical_accuracy: 0.8543 - val_loss: 0.4530 - val_categorical_accuracy: 0.8427\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4315 - categorical_accuracy: 0.8547 - val_loss: 0.4523 - val_categorical_accuracy: 0.8430\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4307 - categorical_accuracy: 0.8548 - val_loss: 0.4518 - val_categorical_accuracy: 0.8424\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4301 - categorical_accuracy: 0.8551 - val_loss: 0.4512 - val_categorical_accuracy: 0.8432\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4294 - categorical_accuracy: 0.8553 - val_loss: 0.4506 - val_categorical_accuracy: 0.8434\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4290 - categorical_accuracy: 0.8558 - val_loss: 0.4503 - val_categorical_accuracy: 0.8435\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4282 - categorical_accuracy: 0.8559 - val_loss: 0.4495 - val_categorical_accuracy: 0.8444\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4277 - categorical_accuracy: 0.8557 - val_loss: 0.4487 - val_categorical_accuracy: 0.8437\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4271 - categorical_accuracy: 0.8562 - val_loss: 0.4484 - val_categorical_accuracy: 0.8449\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4264 - categorical_accuracy: 0.8560 - val_loss: 0.4481 - val_categorical_accuracy: 0.8441\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4260 - categorical_accuracy: 0.8561 - val_loss: 0.4475 - val_categorical_accuracy: 0.8455\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4253 - categorical_accuracy: 0.8558 - val_loss: 0.4474 - val_categorical_accuracy: 0.8437\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4248 - categorical_accuracy: 0.8564 - val_loss: 0.4474 - val_categorical_accuracy: 0.8459\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4244 - categorical_accuracy: 0.8569 - val_loss: 0.4465 - val_categorical_accuracy: 0.8451\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4238 - categorical_accuracy: 0.8568 - val_loss: 0.4455 - val_categorical_accuracy: 0.8462\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4232 - categorical_accuracy: 0.8574 - val_loss: 0.4453 - val_categorical_accuracy: 0.8459\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4228 - categorical_accuracy: 0.8568 - val_loss: 0.4450 - val_categorical_accuracy: 0.8450\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4222 - categorical_accuracy: 0.8575 - val_loss: 0.4442 - val_categorical_accuracy: 0.8448\n"
     ]
    }
   ],
   "source": [
    "## Соберите ну и наконец прокидывание данных\n",
    "## Соберите с батчнормом и релу\n",
    "# прокидываем данные со 2ого слоя на 5ый\n",
    "\n",
    "\n",
    "init = 'he_uniform'\n",
    "act = 'relu'\n",
    "\n",
    "input_tensor = L.Input(shape=(28, 28)) # задаем вход\n",
    "x = L.Flatten()(input_tensor)# применение нейрона к входу\n",
    "x1 = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "x1 = L.BatchNormalization()(x1)\n",
    "x2 = L.Dense(100, kernel_initializer=init, activation=act)(x1)\n",
    "x3 = L.Dense(100, kernel_initializer=init, activation=act)(x2) # повторяем всю логику сколько нам надо раз\n",
    "x4 = L.Dense(100, kernel_initializer=init, activation=act)(x3)\n",
    "x4 = L.BatchNormalization()(x4)\n",
    "x4 = L.concatenate([x2,x4])\n",
    "\n",
    "x5 = L.Dense(100, kernel_initializer=init, activation=act)(x4)\n",
    "output_tensor = L.Dense(10, kernel_initializer=init, activation='softmax')(x)\n",
    "\n",
    "model_complex_first = keras.Model(input_tensor, output_tensor) # Keras под капотом сам собирает граф.\n",
    "# Если он может получить из входа выхода то вы великолепны.\n",
    "\n",
    "model_complex_first.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) \n",
    "\n",
    "history_complex_first = model_complex_first.fit(X_train,y_train_ohe,\n",
    "                                                    batch_size=500,\n",
    "                                                    epochs=100,validation_data = (X_val,y_val_ohe))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 1s 17us/sample - loss: 1.2855 - categorical_accuracy: 0.6127 - val_loss: 0.9382 - val_categorical_accuracy: 0.7180\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.8505 - categorical_accuracy: 0.7398 - val_loss: 0.8096 - val_categorical_accuracy: 0.7468\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.7625 - categorical_accuracy: 0.7617 - val_loss: 0.7501 - val_categorical_accuracy: 0.7608\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.7139 - categorical_accuracy: 0.7742 - val_loss: 0.7123 - val_categorical_accuracy: 0.7728\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.6813 - categorical_accuracy: 0.7844 - val_loss: 0.6853 - val_categorical_accuracy: 0.7796\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6569 - categorical_accuracy: 0.7911 - val_loss: 0.6643 - val_categorical_accuracy: 0.7866\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6378 - categorical_accuracy: 0.7950 - val_loss: 0.6469 - val_categorical_accuracy: 0.7922\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.6219 - categorical_accuracy: 0.8003 - val_loss: 0.6331 - val_categorical_accuracy: 0.7957\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.6087 - categorical_accuracy: 0.8029 - val_loss: 0.6205 - val_categorical_accuracy: 0.7981\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5972 - categorical_accuracy: 0.8066 - val_loss: 0.6105 - val_categorical_accuracy: 0.8003\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5871 - categorical_accuracy: 0.8091 - val_loss: 0.6012 - val_categorical_accuracy: 0.8035\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5782 - categorical_accuracy: 0.8108 - val_loss: 0.5926 - val_categorical_accuracy: 0.8057\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5702 - categorical_accuracy: 0.8131 - val_loss: 0.5856 - val_categorical_accuracy: 0.8082\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5632 - categorical_accuracy: 0.8153 - val_loss: 0.5782 - val_categorical_accuracy: 0.8093\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5565 - categorical_accuracy: 0.8172 - val_loss: 0.5723 - val_categorical_accuracy: 0.8118\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.5505 - categorical_accuracy: 0.8185 - val_loss: 0.5663 - val_categorical_accuracy: 0.8135\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5450 - categorical_accuracy: 0.8200 - val_loss: 0.5611 - val_categorical_accuracy: 0.8151\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5397 - categorical_accuracy: 0.8220 - val_loss: 0.5563 - val_categorical_accuracy: 0.8175\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5352 - categorical_accuracy: 0.8232 - val_loss: 0.5515 - val_categorical_accuracy: 0.8192\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5306 - categorical_accuracy: 0.8250 - val_loss: 0.5471 - val_categorical_accuracy: 0.8207\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5264 - categorical_accuracy: 0.8261 - val_loss: 0.5433 - val_categorical_accuracy: 0.8216\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 1s 10us/sample - loss: 0.5225 - categorical_accuracy: 0.8273 - val_loss: 0.5394 - val_categorical_accuracy: 0.8216\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5187 - categorical_accuracy: 0.8282 - val_loss: 0.5357 - val_categorical_accuracy: 0.8225\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5152 - categorical_accuracy: 0.8292 - val_loss: 0.5327 - val_categorical_accuracy: 0.8233\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5120 - categorical_accuracy: 0.8299 - val_loss: 0.5296 - val_categorical_accuracy: 0.8232\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5087 - categorical_accuracy: 0.8310 - val_loss: 0.5265 - val_categorical_accuracy: 0.8253\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5057 - categorical_accuracy: 0.8323 - val_loss: 0.5232 - val_categorical_accuracy: 0.8262\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.5028 - categorical_accuracy: 0.8325 - val_loss: 0.5206 - val_categorical_accuracy: 0.8276\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.5000 - categorical_accuracy: 0.8335 - val_loss: 0.5183 - val_categorical_accuracy: 0.8265\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4975 - categorical_accuracy: 0.8341 - val_loss: 0.5160 - val_categorical_accuracy: 0.8272\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.4948 - categorical_accuracy: 0.8347 - val_loss: 0.5131 - val_categorical_accuracy: 0.8281\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.4926 - categorical_accuracy: 0.8355 - val_loss: 0.5105 - val_categorical_accuracy: 0.8292\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4902 - categorical_accuracy: 0.8366 - val_loss: 0.5080 - val_categorical_accuracy: 0.8294\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4878 - categorical_accuracy: 0.8376 - val_loss: 0.5061 - val_categorical_accuracy: 0.8299\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4857 - categorical_accuracy: 0.8382 - val_loss: 0.5038 - val_categorical_accuracy: 0.8316\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4837 - categorical_accuracy: 0.8391 - val_loss: 0.5019 - val_categorical_accuracy: 0.8311\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4818 - categorical_accuracy: 0.8391 - val_loss: 0.4999 - val_categorical_accuracy: 0.8328\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4799 - categorical_accuracy: 0.8404 - val_loss: 0.4980 - val_categorical_accuracy: 0.8326\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4779 - categorical_accuracy: 0.8414 - val_loss: 0.4962 - val_categorical_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4762 - categorical_accuracy: 0.8414 - val_loss: 0.4944 - val_categorical_accuracy: 0.8322\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4743 - categorical_accuracy: 0.8421 - val_loss: 0.4929 - val_categorical_accuracy: 0.8337\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4727 - categorical_accuracy: 0.8430 - val_loss: 0.4911 - val_categorical_accuracy: 0.8342\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4711 - categorical_accuracy: 0.8433 - val_loss: 0.4897 - val_categorical_accuracy: 0.8343\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4694 - categorical_accuracy: 0.8433 - val_loss: 0.4880 - val_categorical_accuracy: 0.8361\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4678 - categorical_accuracy: 0.8441 - val_loss: 0.4866 - val_categorical_accuracy: 0.8350\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4664 - categorical_accuracy: 0.8445 - val_loss: 0.4851 - val_categorical_accuracy: 0.8360\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4649 - categorical_accuracy: 0.8453 - val_loss: 0.4841 - val_categorical_accuracy: 0.8353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4637 - categorical_accuracy: 0.8456 - val_loss: 0.4821 - val_categorical_accuracy: 0.8362\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4621 - categorical_accuracy: 0.8461 - val_loss: 0.4816 - val_categorical_accuracy: 0.8375\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4612 - categorical_accuracy: 0.8463 - val_loss: 0.4803 - val_categorical_accuracy: 0.8371\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4596 - categorical_accuracy: 0.8466 - val_loss: 0.4785 - val_categorical_accuracy: 0.8375\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.4583 - categorical_accuracy: 0.8476 - val_loss: 0.4776 - val_categorical_accuracy: 0.8373\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4569 - categorical_accuracy: 0.8476 - val_loss: 0.4760 - val_categorical_accuracy: 0.8369\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4559 - categorical_accuracy: 0.8475 - val_loss: 0.4756 - val_categorical_accuracy: 0.8373\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4548 - categorical_accuracy: 0.8482 - val_loss: 0.4740 - val_categorical_accuracy: 0.8388\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.4536 - categorical_accuracy: 0.8484 - val_loss: 0.4732 - val_categorical_accuracy: 0.8388\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.4524 - categorical_accuracy: 0.8491 - val_loss: 0.4719 - val_categorical_accuracy: 0.8384\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4513 - categorical_accuracy: 0.8492 - val_loss: 0.4707 - val_categorical_accuracy: 0.8394\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4503 - categorical_accuracy: 0.8497 - val_loss: 0.4701 - val_categorical_accuracy: 0.8404\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4493 - categorical_accuracy: 0.8497 - val_loss: 0.4691 - val_categorical_accuracy: 0.8403\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4483 - categorical_accuracy: 0.8505 - val_loss: 0.4679 - val_categorical_accuracy: 0.8405\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4474 - categorical_accuracy: 0.8501 - val_loss: 0.4672 - val_categorical_accuracy: 0.8403\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4464 - categorical_accuracy: 0.8509 - val_loss: 0.4664 - val_categorical_accuracy: 0.8404\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4453 - categorical_accuracy: 0.8509 - val_loss: 0.4653 - val_categorical_accuracy: 0.8405\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4446 - categorical_accuracy: 0.8511 - val_loss: 0.4643 - val_categorical_accuracy: 0.8409\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4435 - categorical_accuracy: 0.8516 - val_loss: 0.4635 - val_categorical_accuracy: 0.8412\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4427 - categorical_accuracy: 0.8513 - val_loss: 0.4627 - val_categorical_accuracy: 0.8409\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4419 - categorical_accuracy: 0.8513 - val_loss: 0.4617 - val_categorical_accuracy: 0.8409\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4410 - categorical_accuracy: 0.8515 - val_loss: 0.4618 - val_categorical_accuracy: 0.8407\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4403 - categorical_accuracy: 0.8523 - val_loss: 0.4603 - val_categorical_accuracy: 0.8410\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4394 - categorical_accuracy: 0.8524 - val_loss: 0.4597 - val_categorical_accuracy: 0.8416\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4384 - categorical_accuracy: 0.8523 - val_loss: 0.4590 - val_categorical_accuracy: 0.8411\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4380 - categorical_accuracy: 0.8525 - val_loss: 0.4583 - val_categorical_accuracy: 0.8428\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4371 - categorical_accuracy: 0.8529 - val_loss: 0.4576 - val_categorical_accuracy: 0.8431\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4364 - categorical_accuracy: 0.8532 - val_loss: 0.4572 - val_categorical_accuracy: 0.8428\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4356 - categorical_accuracy: 0.8534 - val_loss: 0.4562 - val_categorical_accuracy: 0.8428\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4348 - categorical_accuracy: 0.8537 - val_loss: 0.4555 - val_categorical_accuracy: 0.8436\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4341 - categorical_accuracy: 0.8539 - val_loss: 0.4549 - val_categorical_accuracy: 0.8440\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4336 - categorical_accuracy: 0.8540 - val_loss: 0.4543 - val_categorical_accuracy: 0.8443\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4328 - categorical_accuracy: 0.8539 - val_loss: 0.4535 - val_categorical_accuracy: 0.8432\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4321 - categorical_accuracy: 0.8545 - val_loss: 0.4530 - val_categorical_accuracy: 0.8440\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4314 - categorical_accuracy: 0.8540 - val_loss: 0.4529 - val_categorical_accuracy: 0.8444\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4308 - categorical_accuracy: 0.8547 - val_loss: 0.4519 - val_categorical_accuracy: 0.8441\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4302 - categorical_accuracy: 0.8547 - val_loss: 0.4512 - val_categorical_accuracy: 0.8453\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4296 - categorical_accuracy: 0.8550 - val_loss: 0.4507 - val_categorical_accuracy: 0.8440\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4290 - categorical_accuracy: 0.8550 - val_loss: 0.4502 - val_categorical_accuracy: 0.8451\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4283 - categorical_accuracy: 0.8553 - val_loss: 0.4496 - val_categorical_accuracy: 0.8452\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4279 - categorical_accuracy: 0.8559 - val_loss: 0.4494 - val_categorical_accuracy: 0.8446\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4272 - categorical_accuracy: 0.8556 - val_loss: 0.4487 - val_categorical_accuracy: 0.8457\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4266 - categorical_accuracy: 0.8558 - val_loss: 0.4479 - val_categorical_accuracy: 0.8451\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4260 - categorical_accuracy: 0.8558 - val_loss: 0.4475 - val_categorical_accuracy: 0.8455\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4254 - categorical_accuracy: 0.8563 - val_loss: 0.4473 - val_categorical_accuracy: 0.8450\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4250 - categorical_accuracy: 0.8564 - val_loss: 0.4467 - val_categorical_accuracy: 0.8458\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4244 - categorical_accuracy: 0.8564 - val_loss: 0.4467 - val_categorical_accuracy: 0.8452\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4239 - categorical_accuracy: 0.8569 - val_loss: 0.4466 - val_categorical_accuracy: 0.8460\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4235 - categorical_accuracy: 0.8570 - val_loss: 0.4458 - val_categorical_accuracy: 0.8456\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4229 - categorical_accuracy: 0.8572 - val_loss: 0.4449 - val_categorical_accuracy: 0.8456\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4223 - categorical_accuracy: 0.8570 - val_loss: 0.4446 - val_categorical_accuracy: 0.8466\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4220 - categorical_accuracy: 0.8571 - val_loss: 0.4444 - val_categorical_accuracy: 0.8462\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 0s 8us/sample - loss: 0.4214 - categorical_accuracy: 0.8572 - val_loss: 0.4436 - val_categorical_accuracy: 0.8464\n"
     ]
    }
   ],
   "source": [
    "## Соберите ну и наконец прокидывание данных\n",
    "## Соберите с батчнормом и релу\n",
    "# прокидываем данные со 2ого слоя на 5ый\n",
    "\n",
    "\n",
    "init = 'he_uniform'\n",
    "act = 'relu'\n",
    "\n",
    "input_tensor = L.Input(shape=(28, 28)) # задаем вход\n",
    "x = L.Flatten()(input_tensor)# применение нейрона к входу\n",
    "x1 = L.Dense(100, kernel_initializer=init, activation=act)(x)\n",
    "x1 = L.BatchNormalization()(x1)\n",
    "x2 = L.Dense(100, kernel_initializer=init, activation=act)(x1)\n",
    "x3 = L.Dense(100, kernel_initializer=init, activation=act)(x2) # повторяем всю логику сколько нам надо раз\n",
    "x4 = L.Dense(100, kernel_initializer=init, activation=act)(x3)\n",
    "x4 = L.concatenate([x2,x4])\n",
    "x4 = L.BatchNormalization()(x4)\n",
    "x5 = L.Dense(100, kernel_initializer=init, activation=act)(x4)\n",
    "output_tensor = L.Dense(10, kernel_initializer=init, activation='softmax')(x)\n",
    "\n",
    "model_complex_second = keras.Model(input_tensor, output_tensor) # Keras под капотом сам собирает граф.\n",
    "# Если он может получить из входа выхода то вы великолепны.\n",
    "\n",
    "model_complex_second.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) \n",
    "\n",
    "history_complex_second = model_complex_second.fit(X_train,y_train_ohe,\n",
    "                                                    batch_size=500,\n",
    "                                                    epochs=100,validation_data = (X_val,y_val_ohe))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для удобной отрисовки всего\n",
    "\n",
    "def plot_history(histories, key='loss', start=0):\n",
    "    plt.figure(figsize=(16,10))\n",
    "\n",
    "    for name, history in histories:\n",
    "        val = plt.plot(history.epoch[start:], history.history['val_'+key][start:],\n",
    "                       #'--', \n",
    "                       label=name.title()+' Val')\n",
    "            #plt.plot(history.epoch[start:], history.history[key][start:], color=val[0].get_color(),\n",
    "            #     label=name.title()+' Train')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(key.replace('_',' ').title())\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlim([start, max(history.epoch)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history([('simple_BN_and_init', history_simple_BN_and_init),\n",
    "              ('After BN',   history_complex_first),\n",
    "              ('Before BN',   history_complex_second)\n",
    "             ],\n",
    "             start=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Более интересная часть - кастомизация\n",
    "В keras уже есть несколько удобных callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,LearningRateScheduler,ReduceLROnPlateau,ModelCheckpoint,TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.callbacks.ModelCheckpoint"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EarlyStopping # останавливает обучение если наша метрика не меняет n эпох\n",
    "LearningRateScheduler # меняет наш learning_rate по расписанию\n",
    "ReduceLROnPlateau # понижает на LR если не происходит улучшения\n",
    "ModelCheckpoint # сохраняет нашу лучшую модель\n",
    "TensorBoard # Хорошая отрисовка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=3)\n",
    "reduce_on_plateau = ReduceLROnPlateau(patience=3)\n",
    "# filepath=\"checkpoint_path/weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "filepath=\"checkpoint_path/weights-improvement.hdf5\"\n",
    "model_checkpoing = ModelCheckpoint(filepath,\n",
    "                                   save_best_only=True,\n",
    "                                  save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_model():\n",
    "    model = Sequential(name = 'simple_model')\n",
    "    model.add(L.Input(shape = (28,28))) \n",
    "    model.add(L.Flatten()) \n",
    "    model.add(L.Dense(100,  kernel_initializer='random_normal',name='First',activation='relu'))\n",
    "    model.add(L.Dense(100,  kernel_initializer='random_normal',name='Second',activation='relu'))\n",
    "    model.add(L.Dense(10, kernel_initializer = 'random_normal',name='Output',activation='softmax'))\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-4) \n",
    "    model.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "                 metrics=[\"categorical_accuracy\"]) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = create_simple_model()\n",
    "\n",
    "history = model.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [early_stop,reduce_on_plateau,model_checkpoing],verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('checkpoint_path/weights-improvement.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath=\"checkpoint_path/full_model_improvement.hdf5\"\n",
    "model_checkpoing = ModelCheckpoint(filepath,\n",
    "                                   save_best_only=True,\n",
    "                                  save_weights_only=False)\n",
    "simple_model = create_simple_model()\n",
    "\n",
    "history = simple_model.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [early_stop,reduce_on_plateau,model_checkpoing],verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.4337 - categorical_accuracy: 0.8469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4336695870876312, 0.8469]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.evaluate(x=X_val,y=y_val_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Способ писать свои собственные callbacks\n",
    "from tensorflow.keras import callbacks\n",
    " \n",
    "class My_Callback(callbacks.Callback):     # Класс My_Callback унаследовал свойства класса Callback\n",
    "    def on_train_begin(self, logs={}):           # Функция, которая выполняется в начале обучения \n",
    "        return\n",
    " \n",
    "    def on_train_end(self, logs={}):             # Функция, которая выполняется в конце обучения \n",
    "        return\n",
    " \n",
    "    def on_epoch_begin(self, logs={}):           # В начале каждой эпохи \n",
    "        return\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        # В конце каждой эпохи\n",
    "        return\n",
    " \n",
    "    def on_batch_begin(self, batch, logs={}):    # В начале батча\n",
    "        return\n",
    " \n",
    "    def on_batch_end(self, batch, logs={}):      # В конце батча \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "class Printlogs(callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch==10:\n",
    "            print(logs)\n",
    "            self.model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = create_simple_model()\n",
    "our_callback = Printlogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4867748203873634, 'categorical_accuracy': 0.83444, 'val_loss': 0.4964317068457603, 'val_categorical_accuracy': 0.8281}\n"
     ]
    }
   ],
   "source": [
    "history = simple_model.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [our_callback],\n",
    "                           verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.metrics.MeanMetricWrapper at 0x1d069a75048>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.metrics[0]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = simple_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 7, ..., 2, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 7, ..., 1, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_val_ohe,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3433"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(y_val_ohe,axis=1),np.argmax(prediction,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10000000149011612\n",
      "0.05000000074505806\n",
      "0.02500000037252903\n",
      "0.012500000186264515\n",
      "0.0062500000931322575\n",
      "0.0031250000465661287\n",
      "0.0015625000232830644\n",
      "0.0007812500116415322\n",
      "0.0003906250058207661\n",
      "0.00019531250291038305\n",
      "9.765625145519152e-05\n",
      "4.882812572759576e-05\n",
      "2.441406286379788e-05\n",
      "1.220703143189894e-05\n",
      "6.10351571594947e-06\n",
      "3.051757857974735e-06\n",
      "1.5258789289873675e-06\n",
      "7.629394644936838e-07\n",
      "3.814697322468419e-07\n",
      "1.9073486612342094e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Напишем изменение скорости обучения\n",
    "INIT_LR=0.1\n",
    "# Стратегия для понижения скорости\n",
    "def lr_scheduler(epoch):\n",
    "    drop = 0.5\n",
    "    epochs_drop = 1.0\n",
    "    lrate = INIT_LR * np.math.pow(drop, np.math.floor((epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(lr_scheduler)\n",
    "# класс чтобы отслеживать бесчинства\n",
    "class Print_lr(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(float(tf.keras.backend.get_value(self.model.optimizer.lr)))\n",
    "        # чтобы установить свой LR надо указать\n",
    "        # LR_OUR = ....\n",
    "        # tf.keras.backend.set_value(self.model.optimizer.lr, LR_OUR)\n",
    "\n",
    "\n",
    "simple_model = create_simple_model()\n",
    "history = simple_model.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [lrate,Print_lr()],\n",
    "                           verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс чтобы отслеживать бесчинства\n",
    "\n",
    "# Посчитаем дельту в val_metric после каждой эпохи\n",
    "class Print_delta_metrics(callbacks.Callback):\n",
    "    def __init__(self,X_val,y_val_ohe):\n",
    "        self.X_val = X_val\n",
    "        self.y_val_ohe = y_val_ohe\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.metric_start = self.model.evaluate(self.X_val,self.y_val_ohe)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.metric_end = self.model.evaluate(self.X_val,self.y_val_ohe)\n",
    "        print(f'Delta metric on {epoch} equal {-self.metric_end[1]+self.metric_start[1]}')\n",
    "        print(f'Delta loss on {epoch} equal {-self.metric_end[0]+self.metric_start[0]}')\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_callback = Print_delta_metrics(X_val,y_val_ohe)\n",
    "# our_callback.X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 32us/sample - loss: 2.3025 - categorical_accuracy: 0.1016\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 1.5405 - categorical_accuracy: 0.6349\n",
      "Delta metric on 0 equal -0.53329998254776\n",
      "Delta loss on 0 equal 0.7620090757369997\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 1.5405 - categorical_accuracy: 0.6349\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.9658 - categorical_accuracy: 0.6797\n",
      "Delta metric on 1 equal -0.0448000431060791\n",
      "Delta loss on 1 equal 0.5746774916648865\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.9658 - categorical_accuracy: 0.6797\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.7895 - categorical_accuracy: 0.7128\n",
      "Delta metric on 2 equal -0.033100008964538574\n",
      "Delta loss on 2 equal 0.17637987136840816\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.7895 - categorical_accuracy: 0.7128\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.7011 - categorical_accuracy: 0.7504\n",
      "Delta metric on 3 equal -0.03759998083114624\n",
      "Delta loss on 3 equal 0.08837961397171024\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.7011 - categorical_accuracy: 0.7504\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.6411 - categorical_accuracy: 0.7764\n",
      "Delta metric on 4 equal -0.026000022888183594\n",
      "Delta loss on 4 equal 0.059987267017364454\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 0.6411 - categorical_accuracy: 0.7764\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.5997 - categorical_accuracy: 0.7924\n",
      "Delta metric on 5 equal -0.015999972820281982\n",
      "Delta loss on 5 equal 0.04136125946044922\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.5997 - categorical_accuracy: 0.7924\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.5701 - categorical_accuracy: 0.8048\n",
      "Delta metric on 6 equal -0.01239997148513794\n",
      "Delta loss on 6 equal 0.029604255008697566\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.5701 - categorical_accuracy: 0.8048s - loss: 0.5526 - categorical_accuracy\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.5419 - categorical_accuracy: 0.8138\n",
      "Delta metric on 7 equal -0.009000003337860107\n",
      "Delta loss on 7 equal 0.028243283557891852\n",
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.5419 - categorical_accuracy: 0.8138\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.5259 - categorical_accuracy: 0.8195\n",
      "Delta metric on 8 equal -0.005700051784515381\n",
      "Delta loss on 8 equal 0.016036688518524134\n",
      "10000/10000 [==============================] - 0s 25us/sample - loss: 0.5259 - categorical_accuracy: 0.8195\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.5072 - categorical_accuracy: 0.8223\n",
      "Delta metric on 9 equal -0.00279998779296875\n",
      "Delta loss on 9 equal 0.01865286214351658\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.5072 - categorical_accuracy: 0.8223\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.4933 - categorical_accuracy: 0.8296\n",
      "Delta metric on 10 equal -0.007299959659576416\n",
      "Delta loss on 10 equal 0.013937202143669059\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.4933 - categorical_accuracy: 0.8296\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.4825 - categorical_accuracy: 0.8306\n",
      "Delta metric on 11 equal -0.001000046730041504\n",
      "Delta loss on 11 equal 0.010797050857543955\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.4825 - categorical_accuracy: 0.8306\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.4743 - categorical_accuracy: 0.8351\n",
      "Delta metric on 12 equal -0.004499971866607666\n",
      "Delta loss on 12 equal 0.008195980787277235\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.4743 - categorical_accuracy: 0.8351\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.4657 - categorical_accuracy: 0.8371\n",
      "Delta metric on 13 equal -0.0020000338554382324\n",
      "Delta loss on 13 equal 0.008542722606658948\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.4657 - categorical_accuracy: 0.8371\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.4596 - categorical_accuracy: 0.8371\n",
      "Delta metric on 14 equal 0.0\n",
      "Delta loss on 14 equal 0.00615357356071472\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.4596 - categorical_accuracy: 0.8371\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.4521 - categorical_accuracy: 0.8415\n",
      "Delta metric on 15 equal -0.0043999552726745605\n",
      "Delta loss on 15 equal 0.007473820209503157\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.4521 - categorical_accuracy: 0.8415\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.4478 - categorical_accuracy: 0.8419\n",
      "Delta metric on 16 equal -0.0004000067710876465\n",
      "Delta loss on 16 equal 0.0042894207954407015\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.4478 - categorical_accuracy: 0.8419\n",
      "10000/10000 [==============================] - 0s 23us/sample - loss: 0.4418 - categorical_accuracy: 0.8418\n",
      "Delta metric on 17 equal 0.00010001659393310547\n",
      "Delta loss on 17 equal 0.005995493626594517\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.4418 - categorical_accuracy: 0.8418\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 0.4369 - categorical_accuracy: 0.8433\n",
      "Delta metric on 18 equal -0.0015000104904174805\n",
      "Delta loss on 18 equal 0.004889216208457947\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.4369 - categorical_accuracy: 0.8433\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 0.4330 - categorical_accuracy: 0.8459\n",
      "Delta metric on 19 equal -0.0026000142097473145\n",
      "Delta loss on 19 equal 0.003922167587280256\n"
     ]
    }
   ],
   "source": [
    "simple_model = create_simple_model()\n",
    "history = simple_model.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [our_callback],\n",
    "                           verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Давайте заставим модель посчитать метрики каждую эпоху, как пример\n",
    "# Считать будем на X_val, y_val\n",
    "# Посчитаем дельту в val_loss после каждой эпохи\n",
    "# Посчитать через sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кастомные loss и метрики\n",
    "Что уже есть\n",
    "https://keras.io/api/metrics/\n",
    "\n",
    "https://keras.io/api/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "celsius    = np.array([-40, -10,  0,  8, 15, 22,  38],  dtype=float)\n",
    "fahrenheit = np.array([-40,  14, 32, 46, 59, 72, 100],  dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7 samples\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 0s 30ms/sample - loss: 2779.0374\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 0s 142us/sample - loss: 2776.9531\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 0s 142us/sample - loss: 2774.8699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d010ebf088>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam( )\n",
    "\n",
    "model.compile(loss='mse', optimizer=opt)\n",
    "model.fit(celsius, fahrenheit,  epochs=3, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_function(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7 samples\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 0s 36ms/sample - loss: 1132.2122\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 0s 143us/sample - loss: 1131.5636\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 0s 143us/sample - loss: 1130.9163\n",
      "Wall time: 312 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d0156a5f48>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam( )\n",
    "\n",
    "model.compile(loss=custom_loss_function, optimizer=opt)\n",
    "model.fit(celsius, fahrenheit,  epochs=3,verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## тоже самое можно делать и с метриками. Также можно следить сразу за несколькими метриками, что бывает полезно.\n",
    "## Если хотим добавить совсем сложную логику то мы это будем делать через callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой тетрадке немного поработаем с градусами по цельсию и фаренгейту! Снова попробуем восстановить формулу \n",
    "\n",
    "$$ f = c \\times 1.8 + 32 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d017f0eec8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## возьмем срезы\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "model = Sequential()\n",
    "model.add(L.Dense(1,name='our_neural'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(0.1 )\n",
    "\n",
    "model.compile(loss='mse', optimizer=opt)\n",
    "model.fit(celsius, fahrenheit,  epochs=600, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxx_final = np.array([0.])\n",
    "# for i in range(first_layer.variables[0].shape[0]):\n",
    "#     mmax = np.max(first_layer.variables[0][i])\n",
    "#     maxx_final = np.max([maxx_final,mmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26849318"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxx_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'sequential_2/our_neural/kernel:0' shape=(1, 1) dtype=float64, numpy=array([[1.81017952]])>,\n",
       " <tf.Variable 'sequential_2/our_neural/bias:0' shape=(1,) dtype=float64, numpy=array([30.52181683])>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## элементарная задача, но из-за того, что данные не скалированы сходились вечность\n",
    "our_layer = model.get_layer(name='our_neural')\n",
    "our_layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
       "array([[-41.88536396],\n",
       "       [ 12.42002163],\n",
       "       [ 30.52181683],\n",
       "       [ 45.00325299],\n",
       "       [ 57.67450963],\n",
       "       [ 70.34576626],\n",
       "       [ 99.30863858]])>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_layer(np.array(celsius).reshape((7,1))) ## Берем прогнозы от слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(np.array(celsius).reshape((7,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = our_layer.variables[0]\n",
    "b = our_layer.variables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
       "array([[-41.88536396],\n",
       "       [ 12.42002163],\n",
       "       [ 30.52181683],\n",
       "       [ 45.00325299],\n",
       "       [ 57.67450963],\n",
       "       [ 70.34576626],\n",
       "       [ 99.30863858]])>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X@W+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Есть понимание, как взять определить в callback на какой эпохе мы получили правильное значение весов? Проверить как ведет себя наша нейронка? (с учетом того, что мы точно знаем формулу)\n",
    " Ну и заодно быстро проверить гипотезу - а поможет ли нам batchnorm в данной ситуации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hometask\n",
    "1. Взять значение параметров и сравнить их с эталонными. Если разница в значениях меньше эпсилон (вы сами задаете), то считаем, что модель научилась\n",
    "(Взять значение параметров - взять слой от модели и взять значения в этом слое)\n",
    "2. Вывести номер эпохи, когда разница в значениях стала меньше эпсилон\n",
    "3. Повторить упражнение для модели с BN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем класс нейронки с TF и keras вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# транспонировали выборку\n",
    "x_train = celsius[:,None]\n",
    "y_train = fahrenheit[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "class Super_puper_neural_net(keras.Model):\n",
    "    \n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        super(Super_puper_neural_net, self).__init__()\n",
    "        self.fc1 = L.Dense(n_hidden_neurons, kernel_initializer='glorot_uniform',\n",
    "                           activation='sigmoid', trainable=True)\n",
    "        self.fc2 = L.Dense(n_hidden_neurons, kernel_initializer='glorot_uniform',\n",
    "                           trainable=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 1), dtype=float64, numpy=\n",
       "array([[-1.61442909e+00],\n",
       "       [-1.61436408e+00],\n",
       "       [-8.07214544e-01],\n",
       "       [-4.91885342e-04],\n",
       "       [-4.12549632e-07],\n",
       "       [-3.45904655e-10],\n",
       "       [-3.21300131e-17]])>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_super = Super_puper_neural_net(1)\n",
    "model_super.encode(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ошибка для модели\n",
    "def mean_square(y_pred, y_true):\n",
    "    return tf.reduce_mean((y_pred-y_true)**2)\n",
    "\n",
    "# оптимизатор \n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "# процесс оптимизации\n",
    "def model_train(X, Y):\n",
    "\n",
    "    # находим loss и пробрасываем градиент\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = model_super.encode(X)\n",
    "        loss = mean_square(pred, Y)\n",
    "\n",
    "    # Вычисляем градиенты\n",
    "    gradients = g.gradient(loss, model_super.variables)\n",
    "    \n",
    "    # Обновляем веса a и b в ходе одной итерации спуска \n",
    "    optimizer.apply_gradients(zip(gradients, model_super.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 3361.065988\n",
      "step: 100, loss: 2802.970525\n",
      "step: 200, loss: 2415.673370\n",
      "step: 300, loss: 2138.322237\n",
      "step: 400, loss: 1933.152573\n",
      "step: 500, loss: 1776.198660\n",
      "step: 600, loss: 1651.963504\n",
      "step: 700, loss: 1550.323372\n",
      "step: 800, loss: 1464.599027\n",
      "step: 900, loss: 1390.299435\n"
     ]
    }
   ],
   "source": [
    "#Обучение\n",
    "epochs = 1000 # число эпох \n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # Делаем щаг градиентного спуска \n",
    "    model_train(x_train, y_train)\n",
    "    \n",
    "    # Каждую сотую итерацию следим за тем, что произошло\n",
    "    if i%100 == 0:\n",
    "        y_pred = model_super.encode(x_train)\n",
    "        loss_val = mean_square(y_pred, y_train)\n",
    "        print(\"step: %i, loss: %f\" % (i, loss_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Свой слой на Tensorflow для Keras\n",
    "\n",
    "Новые слои можно писать на основе керасовского класса `Layer`. Если прописать `help(tf.keras.layers.Layer)`, можно почитать про него. Если в кратце, нужно реализовать три части: \n",
    "\n",
    "* Конструктор, в нём мы описываем гиперпараметры \n",
    "* Метод `build`, в которм мы описываем все переменные \n",
    "* Метод `call`, который делает forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(L.Layer):\n",
    "    \n",
    "    # Задаём консруктор \n",
    "    def __init__(self, units=32):\n",
    "        super(MyLinear, self).__init__()  # чтобы коректно унаследовались методы\n",
    "        self.units = units                # число нейронов\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # add_weight внутри build то же самое что и Variable, но совместимо с Keras\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal', \n",
    "                                 trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='random_normal', \n",
    "                                 trainable=True)\n",
    "\n",
    "    # Применение \n",
    "    def call(self, inputs):\n",
    "        # сразу делаем и линейное преобразование и ReLU (а почему бы и нет)\n",
    "        return tf.nn.relu(tf.matmul(inputs, self.w) + self.b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_custom = Sequential(name = 'simple_model')\n",
    "model_custom.add(L.Input(shape = (28,28))) \n",
    "model_custom.add(L.Flatten()) \n",
    "model_custom.add(L.Dense(100,  kernel_initializer='random_normal',name='First',activation='relu'))\n",
    "model_custom.add(MyLinear()) ### Самый красивый слой\n",
    "model_custom.add(L.Dense(10, kernel_initializer = 'random_normal',name='Output',activation='softmax'))\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4) \n",
    "model_custom.compile(optimizer=opt,loss='categorical_crossentropy',\n",
    "             metrics=[\"categorical_accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 1s 24us/sample - loss: 2.1697 - categorical_accuracy: 0.4019 - val_loss: 1.9278 - val_categorical_accuracy: 0.4937\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 1s 15us/sample - loss: 1.5984 - categorical_accuracy: 0.5277 - val_loss: 1.3151 - val_categorical_accuracy: 0.5501\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 1s 15us/sample - loss: 1.1363 - categorical_accuracy: 0.6411 - val_loss: 1.0176 - val_categorical_accuracy: 0.6572\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 1s 16us/sample - loss: 0.9295 - categorical_accuracy: 0.6776 - val_loss: 0.8787 - val_categorical_accuracy: 0.6768\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 1s 16us/sample - loss: 0.8209 - categorical_accuracy: 0.7014 - val_loss: 0.7971 - val_categorical_accuracy: 0.7037\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 1s 16us/sample - loss: 0.7503 - categorical_accuracy: 0.7290 - val_loss: 0.7400 - val_categorical_accuracy: 0.7377\n",
      "Epoch 7/20\n",
      "38500/50000 [======================>.......] - ETA: 0s - loss: 0.7057 - categorical_accuracy: 0.7538WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-184-2c19b3f9afe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m history = model_custom.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n\u001b[0;32m      2\u001b[0m                      \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val_ohe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                     callbacks = [early_stop,reduce_on_plateau],verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model_custom.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [early_stop,reduce_on_plateau],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и нам остался пример, как взять срез модели. Посмотреть прогнозы в середине"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_simple_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_21 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "First (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "Second (Dense)               (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train_ohe,batch_size=500,epochs=20,\n",
    "                     validation_data = (X_val,y_val_ohe),\n",
    "                    callbacks = [early_stop,reduce_on_plateau],verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлекаем выходы верхних 2х слоев\n",
    "layer_outputs = [layer.output for layer in model.layers[1:3]]\n",
    "# создаем модель, которая вернет эти выходы с учетом заданнаго входа\n",
    "activation_model = keras.Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = activation_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4.37023959, 1.23396861, 3.51238532, ..., 4.16693784, 1.81672091,\n",
       "         2.20411849],\n",
       "        [6.94814981, 1.14500814, 5.27569097, ..., 2.09566685, 3.48258068,\n",
       "         1.07524494],\n",
       "        [1.07620763, 1.94087692, 0.15785509, ..., 0.25897033, 0.47017189,\n",
       "         0.33243196],\n",
       "        ...,\n",
       "        [4.68589903, 2.05222942, 1.8294265 , ..., 0.        , 2.08374841,\n",
       "         0.32991082],\n",
       "        [1.21789699, 0.89316549, 1.37696869, ..., 1.17656514, 0.74840467,\n",
       "         0.64089733],\n",
       "        [1.09191236, 1.73304391, 1.22410031, ..., 1.06005862, 0.45346914,\n",
       "         0.99722246]]),\n",
       " array([[6.41297614, 4.0618314 , 5.14493456, ..., 0.        , 1.85787004,\n",
       "         2.21333011],\n",
       "        [8.37848403, 0.73636084, 5.23691613, ..., 0.        , 0.        ,\n",
       "         5.53890122],\n",
       "        [1.40693001, 4.11016869, 3.42238888, ..., 0.        , 0.40670065,\n",
       "         0.31541483],\n",
       "        ...,\n",
       "        [0.81557945, 1.4955361 , 0.        , ..., 0.        , 4.38391012,\n",
       "         0.        ],\n",
       "        [3.03714156, 4.85251103, 3.79349022, ..., 0.        , 2.19240426,\n",
       "         0.5956423 ],\n",
       "        [2.43239829, 4.44891253, 3.71013429, ..., 0.        , 1.23220635,\n",
       "         0.78123246]])]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'First_11/Identity:0' shape=(None, 100) dtype=float64>,\n",
       " <tf.Tensor 'Second_9/Identity:0' shape=(None, 100) dtype=float64>]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Что сегодня не вошло - как переопределить градиенты для своих слоев (на уровне keras очень геморойно, если уже занимаетесь этим то вряд ли пишете на верхнеуровневом фраемворке)\n",
    "Как работать с уже готовыми и обучеными моделями, дофичивать нейронки по кусочкам. Но это уже в следующих сериях :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
